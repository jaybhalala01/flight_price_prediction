{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4fead61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot  as plt\n",
    "import seaborn as sn\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "493854f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/home/growlt199/Downloads/manufacturing_project/data/flight_processed_data_wo_stops.csv\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "66004a1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>flight</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "      <th>travel_route</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8709</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "      <td>Delhi-Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>SG-8157</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "      <td>Delhi-Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AirAsia</td>\n",
       "      <td>I5-764</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5956</td>\n",
       "      <td>Delhi-Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-995</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "      <td>Delhi-Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>UK-963</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "      <td>Delhi-Mumbai</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    airline   flight source_city departure_time stops   arrival_time  \\\n",
       "0  SpiceJet  SG-8709       Delhi        Evening  zero          Night   \n",
       "1  SpiceJet  SG-8157       Delhi  Early_Morning  zero        Morning   \n",
       "2   AirAsia   I5-764       Delhi  Early_Morning  zero  Early_Morning   \n",
       "3   Vistara   UK-995       Delhi        Morning  zero      Afternoon   \n",
       "4   Vistara   UK-963       Delhi        Morning  zero        Morning   \n",
       "\n",
       "  destination_city    class  duration  days_left  price  travel_route  \n",
       "0           Mumbai  Economy      2.17          1   5953  Delhi-Mumbai  \n",
       "1           Mumbai  Economy      2.33          1   5953  Delhi-Mumbai  \n",
       "2           Mumbai  Economy      2.17          1   5956  Delhi-Mumbai  \n",
       "3           Mumbai  Economy      2.25          1   5955  Delhi-Mumbai  \n",
       "4           Mumbai  Economy      2.33          1   5955  Delhi-Mumbai  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3aad64ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing colums which i dont want to use in model \n",
    "df.drop(['flight','travel_route'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "66c03b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline</th>\n",
       "      <th>source_city</th>\n",
       "      <th>departure_time</th>\n",
       "      <th>stops</th>\n",
       "      <th>arrival_time</th>\n",
       "      <th>destination_city</th>\n",
       "      <th>class</th>\n",
       "      <th>duration</th>\n",
       "      <th>days_left</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Evening</td>\n",
       "      <td>zero</td>\n",
       "      <td>Night</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SpiceJet</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AirAsia</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Early_Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1</td>\n",
       "      <td>5956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vistara</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Morning</td>\n",
       "      <td>zero</td>\n",
       "      <td>Morning</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Economy</td>\n",
       "      <td>2.33</td>\n",
       "      <td>1</td>\n",
       "      <td>5955</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    airline source_city departure_time stops   arrival_time destination_city  \\\n",
       "0  SpiceJet       Delhi        Evening  zero          Night           Mumbai   \n",
       "1  SpiceJet       Delhi  Early_Morning  zero        Morning           Mumbai   \n",
       "2   AirAsia       Delhi  Early_Morning  zero  Early_Morning           Mumbai   \n",
       "3   Vistara       Delhi        Morning  zero      Afternoon           Mumbai   \n",
       "4   Vistara       Delhi        Morning  zero        Morning           Mumbai   \n",
       "\n",
       "     class  duration  days_left  price  \n",
       "0  Economy      2.17          1   5953  \n",
       "1  Economy      2.33          1   5953  \n",
       "2  Economy      2.17          1   5956  \n",
       "3  Economy      2.25          1   5955  \n",
       "4  Economy      2.33          1   5955  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "82e42af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_one_hot(df):\n",
    "    # get dummy variables for multiple columns\n",
    "    dummy_cols = ['airline', 'departure_time','arrival_time','source_city','destination_city','stops','class']\n",
    "    df1_dummy = pd.get_dummies(df[dummy_cols])\n",
    "\n",
    "    # concatenate original DataFrame with dummy variable DataFrame\n",
    "    df1_concat = pd.concat([df.drop(dummy_cols, axis=1), df1_dummy], axis=1)\n",
    "\n",
    "    # display result\n",
    "    return df1_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "abb7c910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_label_encoding(df):\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "    # Create an instance of LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "\n",
    "    # Specify the list of categorical columns to encode\n",
    "    categorical_columns = ['airline', 'departure_time','arrival_time','source_city','destination_city','stops','class']\n",
    "\n",
    "    # Apply label encoding to each categorical column\n",
    "    for column in categorical_columns:\n",
    "        df[column] = label_encoder.fit_transform(df[column])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e2258be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spilt_data(train_data,test_data):\n",
    "    #create x and y where x are features for the model and y as target\n",
    "    x_train = train_data.drop('price',axis=1)\n",
    "    y_train = train_data['price']\n",
    "\n",
    "    #for test data, create x and y where x are features for the model and y as target\n",
    "    x_test = test_data.drop('price',axis=1)\n",
    "    y_test = test_data['price']\n",
    "    \n",
    "    return x_train,y_train,x_test,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5dab655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spilt_inti_x_y(data):\n",
    "    \n",
    "    #for test data, create x and y where x are features for the model and y as target\n",
    "    x = test_data.drop('price',axis=1)\n",
    "    y = test_data['price']\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "67b7ceb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_train_test(data):\n",
    "    # Split the data into training and testing sets\n",
    "    train_data, test_data = train_test_split(data, test_size=0.2, random_state=123)\n",
    "\n",
    "    # Print the shapes of the train and test sets\n",
    "    #print(\"Training set shape:\", train_data.shape)\n",
    "    #print(\"Testing set shape:\", test_data.shape)\n",
    "    \n",
    "    return train_data,test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "04028b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_random_forest(x_train,y_train,x_test,y_test):\n",
    "\n",
    "    import time\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    #model \n",
    "    regr = RandomForestRegressor(random_state=123)\n",
    "\n",
    "    #training model input as x_train and y_tarin\n",
    "    regr.fit(x_train,y_train)\n",
    "\n",
    "#     print('score on the testing data :-',regr.score(x_test,y_test))\n",
    "#     print('score on the training data :-',regr.score(x_train,y_train))\n",
    "\n",
    "    #model is creted show give x test data as input and retuen predictd data \n",
    "    predictions = regr.predict(x_test)\n",
    "\n",
    "    #MAE\n",
    "    print('MAE:-',metrics.mean_absolute_error(y_test,predictions))\n",
    "\n",
    "    #MSE\n",
    "    print('MSE:-',metrics.mean_squared_error(y_test,predictions))\n",
    "\n",
    "    #RMSE\n",
    "    print('RMSE:-',np.sqrt(metrics.mean_squared_error(y_test,predictions)))\n",
    "\n",
    "    #r2\n",
    "    print(\"r2\",r2_score(y_test, predictions))\n",
    "\n",
    "    # Code or function to measure execution time\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    print(\"Execution time:\", execution_time, \"seconds\")\n",
    "    \n",
    "    return regr,predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c78f346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_into_pickle(model, filename):\n",
    "\n",
    "    # Create the directory if it doesn't exist\n",
    "    directory = os.path.dirname(filename)\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    # Save the model to the specified filename\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2745e379",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_3 = '/home/growlt199/Downloads/manufacturing_project/model_training/model_stacking/meta_model_random_forest_regression.pkl'\n",
    "model_into_pickle(meta_model,filename_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "554c3342",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_model(data, model_path):\n",
    "    # Load the model from the pickle file\n",
    "    with open(model_path, 'rb') as file:\n",
    "        model = pickle.load(file)\n",
    "\n",
    "    # Make predictions on the new data\n",
    "    predictions = model.predict(data)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cad4f044",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testing_new_data(data,filename_1,filename_2,filename_3):\n",
    "    \n",
    "    #convert into one hot and label sncoding \n",
    "    data_1 = data_to_one_hot(train_data)\n",
    "    data_2 = data_label_encoding(train_data)\n",
    "    \n",
    "    # Make predictions on the new data\n",
    "    predictions_1 = predict_with_model(data_1, filename_1)\n",
    "    predictions_2 = predict_with_model(data_2, filename_2)\n",
    "    \n",
    "    # Stack the predictions horizontally\n",
    "    stacked_predictions = np.column_stack((predictions_1, predictions_2))\n",
    "\n",
    "    # Combine original features with stacked predictions\n",
    "    X_stacked = np.column_stack((data_1,data_2,stacked_predictions))\n",
    "    \n",
    "    final_prediction = predict_with_model(X_stacked, filename_3)\n",
    "    \n",
    "    return final_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "db85eacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:- 1111.5046784850927\n",
      "MSE:- 7624049.61665183\n",
      "RMSE:- 2761.168161603315\n",
      "r2 0.9851951059830196\n",
      "Execution time: 44.71833300590515 seconds\n",
      "MAE:- 1132.3560884930785\n",
      "MSE:- 7743512.960197941\n",
      "RMSE:- 2782.7168307605325\n",
      "r2 0.9849631240011275\n",
      "Execution time: 27.36783719062805 seconds\n"
     ]
    }
   ],
   "source": [
    "#final script\n",
    "\n",
    "#split data into two part where one is train main part and econd main test part\n",
    "train_data,test_data = divide_into_train_test(df)\n",
    "\n",
    "#devide train data into data 1 and data 2 for one hot and klabel encoding\n",
    "data_1 = data_to_one_hot(train_data)\n",
    "data_2 = data_label_encoding(train_data)\n",
    "\n",
    "#divide data1 and data 2 into two part train and test\n",
    "train_data_1,test_data_1 = divide_into_train_test(data_1)\n",
    "train_data_2,test_data_2 = divide_into_train_test(data_2)\n",
    "\n",
    "#divide train test into fetures and target\n",
    "X_train_1,y_train_1,X_test_1,y_test_1=spilt_data(train_data_1,test_data_1)\n",
    "X_train_2,y_train_2,X_test_2,y_test_2=spilt_data(train_data_2,test_data_2)\n",
    "\n",
    "#model train part \n",
    "model_1,predictions_1 = model_random_forest(X_train_1,y_train_1,X_test_1,y_test_1)\n",
    "model_2,predictions_2 = model_random_forest(X_train_2,y_train_2,X_test_2,y_test_2)\n",
    "\n",
    "#dump in pickle file \n",
    "filename_1 = '/home/growlt199/Downloads/manufacturing_project/model_training/model_stacking/model_1_random_forest_regression.pkl'\n",
    "filename_2 = '/home/growlt199/Downloads/manufacturing_project/model_training/model_stacking/model_2_random_forest_regression.pkl'\n",
    "\n",
    "model_into_pickle(model_1,filename_1)\n",
    "model_into_pickle(model_2,filename_2)\n",
    "\n",
    "# Stack the predictions horizontally\n",
    "stacked_predictions = np.column_stack((predictions_1, predictions_2))\n",
    "\n",
    "# Combine original features with stacked predictions\n",
    "X_stacked = np.column_stack((X_test_1,X_test_2, stacked_predictions))\n",
    "\n",
    "# Second-level model\n",
    "meta_model = RandomForestRegressor()\n",
    "\n",
    "# Train the second-level model using combined features\n",
    "meta_model.fit(X_stacked, y_test_1)\n",
    "\n",
    "#dump into pickle file\n",
    "filename_3 = '/home/growlt199/Downloads/manufacturing_project/model_training/model_stacking/meta_model_random_forest_regression.pkl'\n",
    "model_into_pickle(meta_model,filename_3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b81397",
   "metadata": {},
   "source": [
    "# testing in new data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e5730eec",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- airline\n- arrival_time\n- class\n- departure_time\n- destination_city\n- ...\nFeature names seen at fit time, yet now missing:\n- airline_AirAsia\n- airline_Air_India\n- airline_GO_FIRST\n- airline_Indigo\n- airline_SpiceJet\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m test_data_x,test_data_y \u001b[38;5;241m=\u001b[39m spilt_inti_x_y(test_data)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#final prediction \u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m final_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtesting_new_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilename_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilename_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfilename_3\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#MAE\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE:-\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m.\u001b[39mmean_absolute_error(test_data_y,final_predictions))\n",
      "Cell \u001b[0;32mIn[62], line 8\u001b[0m, in \u001b[0;36mtesting_new_data\u001b[0;34m(data, filename_1, filename_2, filename_3)\u001b[0m\n\u001b[1;32m      5\u001b[0m data_2 \u001b[38;5;241m=\u001b[39m data_label_encoding(train_data)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Make predictions on the new data\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m predictions_1 \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_with_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m predictions_2 \u001b[38;5;241m=\u001b[39m predict_with_model(data_2, filename_2)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Stack the predictions horizontally\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[61], line 7\u001b[0m, in \u001b[0;36mpredict_with_model\u001b[0;34m(data, model_path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(file)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Make predictions on the new data\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:981\u001b[0m, in \u001b[0;36mForestRegressor.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    979\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# Check data\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_X_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[1;32m    984\u001b[0m n_jobs, _, _ \u001b[38;5;241m=\u001b[39m _partition_estimators(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_estimators, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:602\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;124;03mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[1;32m    601\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 602\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(X) \u001b[38;5;129;01mand\u001b[39;00m (X\u001b[38;5;241m.\u001b[39mindices\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc \u001b[38;5;129;01mor\u001b[39;00m X\u001b[38;5;241m.\u001b[39mindptr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m np\u001b[38;5;241m.\u001b[39mintc):\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[1;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[1;32m    490\u001b[0m ):\n\u001b[1;32m    491\u001b[0m     \u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[1;32m    492\u001b[0m \n\u001b[1;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    554\u001b[0m         )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sklearn/base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[1;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    479\u001b[0m     )\n\u001b[0;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[0;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- airline\n- arrival_time\n- class\n- departure_time\n- destination_city\n- ...\nFeature names seen at fit time, yet now missing:\n- airline_AirAsia\n- airline_Air_India\n- airline_GO_FIRST\n- airline_Indigo\n- airline_SpiceJet\n- ...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#final test\n",
    "test_data_x,test_data_y = spilt_inti_x_y(test_data)\n",
    "\n",
    "#final prediction \n",
    "final_predictions = testing_new_data(test_data_x,filename_1,filename_2,filename_3)\n",
    "\n",
    "#MAE\n",
    "print('MAE:-',metrics.mean_absolute_error(test_data_y,final_predictions))\n",
    "\n",
    "#MSE\n",
    "print('MSE:-',metrics.mean_squared_error(test_data_y,final_predictions))\n",
    "\n",
    "#RMSE\n",
    "print('RMSE:-',np.sqrt(metrics.mean_squared_error(test_data_y,final_predictions)))\n",
    "\n",
    "#r2\n",
    "print(\"r2\",r2_score(test_data_y, final_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bcfbd0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#final test\n",
    "test_data_x,test_data_y = spilt_inti_x_y(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61192772",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be755e30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
